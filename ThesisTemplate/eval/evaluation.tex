\chapter{Evaluation \& Testing}\label{ch:Evaluation}

\section{Results from the three series of experiments}
\subsection{Random Forest: algorithm baseline performance}
As explained in Chapter 4, the first experiment to be conducted was to feed the datasets through  a Random Forest algorithm and record the performance metrics for each dataset as a baseline to compare the results of the following experiments to.

The confusion matrix was obtained from the RandomForestModelling script for each dataset is shown in appendix D1-D10 and was used to further interpret the data shown in table 5.1.\newline
Table 5.1 shows the results obtained for each dataset. There are three occasions where the performance metrics were not calculated:
\begin{itemize}
    \item The precision value for the Fertility dataset
    \item The F1 value for the Fertility dataset
    \item The F1 value for the modified Heart Attack dataset
\end{itemize}

\begin{table}[!htbp]
\centering
\begin{tabular}{lrrrr}
  \hline
  \rowcolor{LightCyan}
Dataset & Accuracy & Sensitivity & Precision & F1Score \\ 
  \hline
AuSDf & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  BCDf & 0.92 & 0.86 & 0.94 & 0.89 \\ 
  CCDf & 1.00 & 0.90 & 1.00 & 0.95 \\ 
  DiabetesDf & 0.74 & 0.56 & 0.72 & 0.63 \\ 
  FertDf & 0.93 & 0.00 & nd & nd \\ 
  HAPDf & 0.91 & 0.83 & 0.89 & 0.86 \\ 
  LBPDf & 0.82 & 0.90 & 0.84 & 0.87 \\ 
  LiverDf & 0.72 & 0.35 & 0.58 & 0.44 \\ 
  subHAPDf & 0.95 & 0.00 & 0.00 & nd \\ 
  subLBPDf & 0.91 & 0.50 & 1.00 & 0.67 \\ 
   \hline
\end{tabular}
\end{table}

The data from the confusion matrix output for the Fertility test (Appendix D.5)
show that there were no accurate prediction for the positive class and no inaccurate prediction for the positive class which means the the Precision or Positive predictive value could not be calculated (no division by 0) for this dataset. A lack of Precision value means that the F1 score cannot be calculated as it is obtained by calculated the harmonic mean of Precision and Sensitivity.\newline
This result is partly due to the size of the dataset (only 100 observations and as such there are only 29 observations in the test set). This means that the model will very accurately predict people not suffering infertility but struggles to identify people suffering from infertility.\newline
There is no value for the F1 score of the modified Heart Attack dataset as both the Precision and Sensitivity values are equal to 0 and as such the harmonic mean cannot be calculated (no division by 0).

Table 5.1 also shows that only considering overall accuracy when estimating the performance of an algorithm is misleading. Random Forest returns good to very good accuracy for most of these datasets (accuracy ranges from 0.72 to 1), however, excluding the Autism dataset, the Sensitivity, Precision and F1 score obtained can indicate that although the accuracy is good there is a high chance of the algorithm returning a high number of false positives or missing out positives. \newline
Since in all cases except the Low Back Pain dataset, there is a majority of cases for the negative class, this is expected and experimenting with under-sampling and over-sampling of the data may lead to improvement of some of the metrics.


\subsection{Under-sampling of the majority class}
\subsubsection{Retaining 40\% of the majority class}



\subsubsection{Retaining 60\% of the majority class}


\subsubsection{Retaining 75\% of the majority class}


\subsection{Over-sampling the minority class (SMOTE)}





\section{Impact of under-sampling and over-sampling on the performance of the algorithms}




 
\section{Conclusions}

The main conclusions for this chapter.


