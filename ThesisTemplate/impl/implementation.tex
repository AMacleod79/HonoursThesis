\chapter{Implementation}\label{ch:Implementation}

\section{Exploratory Data Analysis}
All code for the EDA detailed in this chapter can be found at:\newline https://github.com/AMacleod79/HonoursProjectCode
\subsection{Data Overview}
% add modification to dataset to replicate real life incidence?
A total of eight health related datasets were chosen to examine the problem of class imbalance. As previously detailed in chapter 3, these datasets were publicly available on kaggle.com and having already been processed to some extent to either anonymise the data or render the data more workable. The extent of class imbalance varied across the different datasets and for some the imbalance was not very severe at all. In all cases a modified version of the dataset was created to attempt to replicate the real-life prevalence of the disease.\newline

\subsubsection{Cervical cancer dataset}
The cervical cancer dataset was obtained from kaggle.com. \newline
(see https://www.kaggle.com/loveall/cervical-cancer-risk-classification)\newline
This dataset looks at predicting cervical cancer diagnostic based on well known risk factors. Cervical cancer is a complicated diagnostic to make and as such there is not one single test to confirm diagnostic. A diagnostic column was created as an average from the four possible diagnostic test used  (last four column: Hinselmann, Schiller, Citology, Biopsy ) \cite{Fernandes:2017td} %add the Wen paper too.
The dataset contains 858 instances with 32 features and 4 target variables for each of the test carried out.
The exploratory data analysis carried out on this dataset can be found in the cited github repository as CervicalCancerEDA.R.
The 32 features focus on lifestyle factors previously shown to influence cervical cancer risk in women, namely:
\begin{itemize}
    \item Age
    \item Number of sexual partners
    \item First sexual intercourse (age)
    \item Num of pregnancies
    \item Smokes (boolean)
    \item Smokes (years)
    \item Smokes (packs/year)
    \item Hormonal Contraceptives (boolean)
    \item Hormonal Contraceptives (years)
    \item IUD (boolean)
    \item IUD (years)
    \item STDs (boolean)
    \item STDs (number)
    \item STDs:condylomatosis (boolean)
    \item STDs:cervical condylomatosis (boolean)
    \item STDs:vaginal condylomatosis (boolean)
    \item STDs:vulvo-perineal condylomatosis (boolean)
    \item STDs:syphilis (boolean)
    \item STDs:pelvic inflammatory disease (boolean)
    \item STDs:genital herpes (boolean)
    \item STDs:molluscum contagiosum (boolean)
    \item STDs:AIDS (boolean)
    \item STDs:HIV (boolean)
    \item STDs:Hepatitis B (boolean)
    \item STDs:HPV (boolean)
    \item STDs: Number of diagnosis
    \item STDs: Time since first diagnosis
    \item STDs: Time since last diagnosis
    \item Dx:Cancer (previous diagnostic of cervical cancer)
    \item Dx:CIN (previous diagnostic of cervical intreaepithelial neoplasia)
    \item Dx:HPV (previous diagnostic of HPV)
    \item Dx (previous diagnostic of cervical cancer)
    \item Hinselmann (target variable)
    \item Schiller (target variable)
    \item Citology (target variable)
    \item Biopsy (target variable)
\end{itemize}

The exact meaning of each variable was not always straight forward to understand as the data was uploaded to kaggle by someone else than the original authors. The UCI repository also gives access to the data with scant details on the meaning of each column. The original work by Fernandes and colleagues \cite{Fernandes:2017td} does not clearly define each of the column and the link to the dataset from the published article now returns a 404 error. With these considerations in mind and based on other work carried out by other authors (Wen and colleagues), the above attributes were used and a composite target variable was created (see below).
An examination of the data structure showed that 27 columns were factors, with the column "smoke pack per year" showing 63 levels. The Random Forest function in R will only handle a maximum of 53 levels and therefore the data in this column needed to be manipulated to accommodate this restriction. First any missing values was replaced by the mean for the column. Then it was found that there were a high number of discrete values between 0 and 1 for the number of pack of cigarettes smoked per year, and these were all considered as independent levels. All values that were less than 1 for this column were replaced by 0, taking the total number of levels for the column from 63 to 42, which is now manageable by Random Forest.
All the other columns had a number of factor levels smaller than 53 and were left as such, however any missing value was replaced by the mean for the column in which it was found.
A composite target variable calculated as a mean value of all 4 target variables (Hinselmann, Schiller, Citology, Biopsy was created and added as the last column in the dataset (rounded to 0 or 1).
Finally the class distribution was represented as a bar chart and detailed in a table (see Figure 4.1 and table 4.1) and the modified dataset was exported as a new csv file to be used in the later stages of this projects.

\subsubsection{Breast cancer dataset}
This dataset was obtained from kaggle.com. \newline
(see https://www.kaggle.com/uciml/breast-cancer-wisconsin-data) \newline
This dataset was developed with a view to train and test algorithms to determine whether a breast tumour was malignant or benign \cite{}. \newline
The dataset is comprised of 569 instances each with 32 attributes and one target label (B for benign and M for malignant).\newline
The attributes were computed from images of a fine needle aspirate of a breast mass to describe the characteristics of the cell nuclei present in the image. The features were as follows:
\begin{itemize}
    \item radius (mean of distances from center to points on the perimeter)
    \item texture (standard deviation of gray-scale values) 
    \item perimeter 
    \item area 
    \item smoothness (local variation in radius lengths) 
    \item compactness (perimeter\^2 / area - 1.0)
    \item concavity (severity of concave portions of the contour)
    \item concave points (number of concave portions of the contour)
    \item symmetry
    \item fractal dimension ("coastline approximation" - 1)
\end{itemize}
The mean, standard error and mean of of three largest values (i.e. the "worst") for each of the feature was calculated and documented as a feature for each image.\newline

The exploratory data analysis carried out on this dataset is documented in the cited github repository as BreastCancerEDA.R.\newline
An analysis of the data structure showed no missing values. The target variable was expressed as B or M and was recoded to be either 0 (benign) or 1 (malignant), further the target variable was originally the second column but for ease of analysis in the next stages of the project this was moved to be the last column and renamed "Label".
Finally the class distribution of the dataset was computed and is shown in figure 4.1 with details shown in table 4.1 the modified dataset was exported as a csv file for later use in the project.\newline


\subsubsection{Liver Disease dataset}
This dataset was obtained from kaggle.com.\newline
(see https://www.kaggle.com/jeevannagaraj/indian-liver-patient-dataset). \newline

This dataset is made up of 583 instances of patient records with 10 attributes and one target variable to determine whether the patient is a liver patient or not. The attributes are various biochemical measures of liver health as well as patient specific information such as age and gender:
\begin{itemize}
    \item Age of patient
    \item Gender of patient
    \item Total Bilirubin
    \item Direct Bilirubin
    \item Alkaline Phosphatase
    \item Alamine Amino-transferase (sgpt)
    \item Aspartate Amino-transferase (sgot)
    \item Total Proteins
    \item Albumin
    \item Albumin and Globulin Ratio
    \item is patient (target label)
\end{itemize}

The exploratory data analysis carried out on this dataset is documented in the cited github repository as LiverDataEDA.R.\newline
The target label was set to 1 (not a liver patient) and 2 (liver patient), for consistency with respect to the other datasets used in this project, the data was recoded to 0 (not a liver patient) and 1 (liver patient).\newline
A check for missing data revealed only four instances missing a value in the albumin and globulin ratio. The missing values were replaced with the mean for that column.\newline
The class distribution was compiled and presented as a graph (see figure 4.1) and the details of the class distribution were shown in table 4.1. The modified dataset was exported as a csv file for later use in the project.\newline

\subsubsection{Diabetes}
This dataset comprise 768 instances of health data from female Pima Indian patients of at least 21 years of age. There are 8 attributes and one target variable. The target variable indicates whether the individual will develop diabetes within 5 years (1) or not (0). The attributes were as follows:
\begin{itemize}
    \item Pregnancies indicates the number of times the patient pregnant
    \item GlucosePlasma indicates the glucose concentration at 2 hours in an oral glucose tolerance test
    \item BloodPressureDiastolic indicates the diastolic blood pressure (mm Hg)
    \item SkinThicknessTriceps indicates triceps skin fold thickness ( in mm)
    \item Insulin2-Hour indicates the serum insulin concentration  (mu U/ml)
    \item BMI indicates body mass index (weight in kg/(height in m \textsuperscript{2})
    \item DiabetesPedigreeFunctionDiabetes is a pedigree function calculated by the original authors of the study which takes family history of diabeted into account
    \item Age records the age of the patient (years)
\end{itemize}
 The dataset was used in a study looking at the ADAP algorithm and further details about the pedigree function and other variables can be found in the article \cite{Smith:1988wy}.
 
The exploratory data analysis carried out on this dataset is documented in the cited github repository as DiabetesEDA.R.\newline
The target label was already set to 0 (did not develop diabetes within 5 years) and 1 (did develop diabetes within 5 years), so no recoding of the data was necessary.\newline
A check for missing data revealed none, and Smith \textit{et al.,} indicate that they replaced any missing data with 0 (which does not always make sense, e.g. for blood pressure). No further modification of the dataset were necessary and the dataset was saved as csv file for later use.
The class distribution was compiled and presented as a graph (see figure 4.1) and details of the class distribution can be seen in table 4.1. The dataset was saved as a csv file for later use in the project.

\subsubsection{Lower Back Pain dataset}
% need citations
This dataset was originally built by Dr Henrique da Mota with a view to classify patient as one of 3 class: Normal, patients with disk hernia and patients with spondylolisthesis. In a second classifying task, the two types of sufferers were grouped as one abnormal category. This dataset was first uploaded to UCI (see http://archive.ics.uci.edu/ml/datasets/vertebral+column#) and then uploaded to Kaggle (see https://www.kaggle.com/sammy123/lower-back-pain-symptoms-dataset) as a binary classification task dataset (normal/abnormal).\newline
The dataset consists of 310 instances with 13 attributes (12 numeric predictors and 1 target label) as follows:
\begin{itemize}
    \item pelvic incidence
    \item pelvic tilt
    \item lumbar lordosis angle
    \item sacral slope
    \item pelvic radius
    \item degree spondylolisthesis
    \item pelvic slope
    \item Direct tilt
    \item thoracic slope
    \item cervical tilt
    \item sacrum angle
    \item scoliosis slope
\end{itemize}

The exploratory data analysis for this dataset is documented in the cited github repository as LowBackPainEDA.R.\newline
For ease of reading and  manipulation, the columns names were replaced by the actual name of the predictor (removing col x from the name) and the unused column X was removed.\newline
The target label was set as abnormal or normal so the data was recoded to be 1 for abnormal and 0 for normal, in line with the other datasets.
There were no missing values in the dataset.
Uncharacteristically for a classification task, the abnormal class contains a higher number of instances than the normal class (see figure 4.1 and table 4.1). This is unusual and in order to observe a class distribution more in line with those seen in other datasets in this project, random sampling of the dataset was  carried out so as to create a modified dataset with more normal samples than abnormal. To obtain the new dataset, 7\% of the abnormal instances were  retained (resulting in a higher prevalence than current estimates of 1-3\% of low back pain sufferer) %citation needed here

and 100 \% of the normal instances were retained. The new class distribution is also shown on figure 4.1 with details outlined in table 4.1.\newline

\subsubsection{Heart Attack Dataset}
This dataset is a subset from a multi-centre, larger study which looked at patients with and without heart disease. The dataset was obtained from kaggle.\newline 
(see https://www.kaggle.com/imnikhilanand/heart-attack-prediction) \newline
The complete dataset appears to be available from UCI:\newline
https://archive.ics.uci.edu/ml/datasets/heart+Disease \newline 
though some of the files may be corrupted and the classification tasks of the original datasets is not binary.
The original dataset was made up of 76 predictors but in this dataset this has been reduced to 13 and a target variable:
\begin{itemize}
    \item age (in years)
    \item sex (1 = male, 0 = female) 
    \item cp (chest pain type 1-4)
    \item trestbps (resting blood pressure)
    \item chol (serum cholesterol in mg/dl) 
    \item fbs (fasting blood sugar >120 mg/dl, 1= true, 0 =false) 
    \item restecg (resting ECG results - 0 = normal, 1 = ST-T abnormal, 2 = hypertrophy)
    \item thalach (maximum heart rate achieved)
    \item exang (exercise induced angina 1 = yes, 0 = no)
    \item oldpeak (ST depression induced by exercise)
    \item slope (slope of peak exercise ST segment)
    \item ca (number of major vessels coloured fluoroscopy (0-3) 
    \item thal (3 = normal, 6 = fixed defect, 7 = reversable defect) 
\end{itemize}

The exploratory data analysis is documented in the cited github repository as HeartAttackEDA.R.\newline
Nine column contained missing values, and those were replaced with the mean value for that column. Examination of the data structure revealed that columns "chol" (for cholesterol value) and "thalach" (maximum heart rate achieved) were factors with more than 53 levels (the maximum that can be handled by Random Forest), 154 and 72 levels, respectively. The number of levels was reduced by grouping levels into categories:
\begin{table}[!htbp]
\centering
\caption{Grouping of levels for columns "chol" and "thalach" (Heart Disease Dataset)}
\begin{tabular}{*5c}
  \hline
  \rowcolor{LightCyan}
  \multicolumn{2}{c}{Cholesterol} & \multicolumn{2}{c}{Thalach} \\
  \hline
  \hline
Level Value & New Level & Level Value & New Level\\ 
  \hline
    $<$100  & 100 & $\leq$90 & 90 \\ 
   $<$175 $\leq$150 & 175 & $>$90 $\leq$95   &  95 \\ 
  $<$200 $\geq$175 & 200 & $>$95 $\leq$100  & 100  \\ 
   $>$200 $\leq$225 & 225 & $>$100 $\leq$105 & 105  \\ 
   $>$225 $<$250  & 250 & $>$105 $\leq$110 & 110  \\ 
   $>$250 $<$275  & 275 & $>$110 $\leq$115 & 115  \\ 
   $>$275 $<$300  & 300 & $>$115 $\leq$120 & 120   \\ 
   $>$300 $<$325  & 325 & $>$120 $\leq$125 & 125   \\ 
   $>$325 $<$350  & 350 & $>$125 $\leq$130 & 130  \\ 
   $>$350 $<$375  & 375 & $>$130 $\leq$135 & 135  \\ 
   $>$375 $<$400  & 400 & $>$135 $\leq$140 & 140 \\ 
   $>$400 $<$425  & 425 & $>$140 $\leq$145 & 145\\ 
   $>$425 $<$450  & 450 & $>$145 $\leq$150 & 150\\ 
   $>$450 $<$475  & 475 & $>$150 $\leq$155 & 155\\ 
   $>$475 $<$500  & 500 & $>$155 $\leq$160 & 160\\ 
  `$>$500 $<$525  & 525 & $>$160 $\leq$165 & 165 \\ 
   $>$525 $<$550  & 550 & $>$165 $\leq$170 & 170 \\ 
   $>$550 $<$575  & 575 & $>$170 $\leq$175 & 175 \\ 
   $>$575 $<$600  & 600 & $>$175 $\leq$180 & 180 \\ 
                  &     & $>$180 $\leq$185 & 185 \\ 
                  &     & $>$185 $\leq$190 & 190 \\ 
   \hline
\end{tabular}
\end{table}

The target label was already set as either 0 (no heart disease) or 1 (heart disease) so this did not need to be modified. 
The class distribution is shown on Figure 4.1 and detailed in table 4.3. The modified dataset was save as a csv file for further use in the project.

This dataset is fairly balanced. In order to create a more imbalanced dataset, random sampling of the data which will retain all of the "normal" cases and only 10\% of the "positive" cases was carried out. The modified dataset was saved for future use in the project. The new class distribution is also shown in figure 4.1 (with break down in table 4.3) and reflects real-life prevalence of heart disease in the UK (6.7\% in men and 4.2\% in women) \citep{}\newline

\subsubsection{Autism dataset}
The Autism dataset was obtained from kaggle.com:\newline
https://www.kaggle.com/faizunnabi/autism-screening\newline
This dataset examines the predicting factors for someone to have autism or not, based on 10 behavioural features and 10 individual characteristics. The dataset was originally created by Thabtah and colleagues \citep{} and further details can be found in their various publications \cite{}.\newline
The dataset comprising of 704 observations with 21 attributes and 1 target variable (does the patient have autism or not):\newline
\begin{itemize}
    \item A1 Score 
    \item A2 Score
    \item A3 Score 
    \item A4 Score
    \item A5 Score
    \item A6 Score
    \item A7 Score
    \item A8 Score
    \item A9 Score
    \item A10 Score
    \item age
    \item gender
    \item ethnicity 
    \item jundice (born with jaundice or not)
    \item austim (relative with PDD or not)
    \item country of res
    \item used app before (used the screening app before)
    \item result (score to the questionnaire)
    \item age desc (under 18 or not)
    \item relation (questionnaire filled by self or other)
    \item Class/ASD
\end{itemize}

A1 to A10 score represent the answer to each of the 10 question (binary) of a questionnaire for screening based on behaviour. 
The class label for this dataset is No (for not autistic) and yes (for autistic), so the data was recoded to be consistent with the other datasets to 0 for No and 1 for Yes.
There were some missing values for the age column which were replaced with the mean value for the column. The na values for the ethnicity and relation columns were replaced by "unknown". Finally the country of residence column contained 67 different levels which is too many for Random Forest to handle.  Examination of the distribution of the data per country of residence showed that although some countries showed higher proportion of autism patients than others, in many cases the samples sizes were very small (less than 5) and therefore likely to be biaised one way or the other (see appendix). For that reason, it was felt that, although the countries of residence could have been grouped by continent or geographical zones, this column could be dropped without affecting the performance of the algorithm. 

\subsubsection{Fertility dataset}
This dataset was obtained from Kaggle:\newline
https://www.kaggle.com/gabbygab/fertility-data-set \newline
The data gathered aims to examine the predictors for altered fertility. This data was used in work by Gil and colleagues \cite{} This is a small set of 100 observations with 9 variables and a target label:
\begin{itemize}
    \item Season (Season in which the analysis was performed)
    \item Age (Age at the time of analysis)
    \item Childhood diseases
    \item Accident or serious trauma
    \item Surgical intervention
    \item High fevers in the last year
    \item Frequency of alcohol consumption
    \item Smoking habit
    \item Number of hours spent sitting per day
    \item Diagnosis
\end{itemize}







\subsection{Class distribution comparisons between datasets}


\begin{table}[H]
\centering
\begin{tabular}{lrr}
  \hline
Datasets & Majority.Class & Minority.Class \\ 
  \hline
Cervical\_Cancer & 95.45 & 4.55 \\ 
  Breast\_Cancer & 62.74 & 37.26 \\ 
  Liver\_Disease & 71.36 & 28.64 \\ 
  Diabetes & 65.10 & 34.90 \\ 
  Lower\_Back\_Pain & 67.74 & 32.26 \\ 
  Lower\_Back\_Pain modified & 87.72 & 12.28 \\ 
  Heart\_Attack & 63.95 & 36.05 \\ 
  Heart\_Attack modified & 94.95 & 5.05 \\ 
  Autism & 73.15 & 26.85 \\ 
  Fertility & 88.00 & 12.00 \\ 
   \hline
\end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{ThesisTemplate/usingLatex/chapter4Images/figure4_1b.png}
    \caption{Class Distribution of the chosen datasets.\newline In all cases the majority class is the class representing healthy subjects and the minority class is the class representing affected subjects. In the case of the lower back pain dataset, the class representing the "abnormal" patients counts more instances than the the class representing the "normal" patients, however the terms minority and majority were kept for consistency with the other datasets.}
    \label{fig:my_label}
\end{figure}
\section{Modelling the datasets}
\subsection{Random Forest}
Random forest was used with all the datasets. An R script (see linked repository, Experiment1.R and RandomForestModelling.R) was created to classify all 10 datasets and obtain a baseline of the performance that could be obtained on the mostly untouched data.
The dataset were uploaded as a list which was iterated through by the R function randomForest. The data split was 70:30 train: test and the number of trees was 1000, proximity and importance were both set as true.\newline
The RandomForestModelling.R script allowed for a data frame to be created to contain performance metrics of the algorithm for each dataset.\newline
The performance metrics used were Accuracy, sensitivity, precision and F1 score.\newline

\subsection{Support Machine Vector}
\subsection{K-Nearest Neighbour}
\subsection{Naive  Bayes}
\section{Modelling the datasets with data-level solutions applied}
\subsection{Undersampling of the majority class}
\subsubsection{Undersampling majority class: 40\%}
An R script was created to fit Random Forest to the datasets after under sampling the majority class in an attempt to address the class imbalance. This will lead to loss of data and though we expect some metrics to improve it is likely that others will also worsen.\newline
A function to choose the proportion of each class to include in the experiment was devised and several different percentages of majority class data were tested, while always retained 100 \% of the minority class.  The default value for the function was 40\% of the majority class and 100\% of the minority class retained. The same experiment was also carried out for 60\% of majority class and 75\% of majority class.\newline
\subsubsection{Undersampling majority class: 60\%}
In each case the accuracy, sensitivity precision and F1 score were recorded.\newline

\subsubsection{Undersampling majority class: 60\%}

\subsection{Oversampling of the minority class}
Experiment 3 Oversampling of the minority class
This time, in order to address the class imbalance, the SMOTE function was applied to the datasets. SMOTE (Synthetic Minority Oversampling Technique) is a technique devised in 2002 (citation). A smote()  R function exists in package DMwR and was used for these experiments.\newline
%Here detail the smote function
The k value is set by default at k=5. This value needs to be set to 3 or 4 for the modified heart attack dataset since there so few observations in the training sets after the data has been split. if k exceeds the number of minority class observations in the training set, an error will occur as there will not be enough points to create the new data point.\newline
The smote() function is applied only to the training set, not the testing set.\newline

The parameters used when applying smote to the non modified datasets were  k=4


The smote() function was applied to the modified heart attack dataset and low back pain dataset with separate parameters from the other datasets, as the generally lower number of observation existing in the sample meant that too few majority class observations were retained. The parameters for these datasets were 200, 600 and k= 4.
Finally the fertility datasets consists of a low number of observation and smote() was also applied with separate parameters so as to retain a larger number of majority class observation (200, 600 k=4) % check those numbers.




 



\subsection{k-mean}


\section{Modelling the datasets with algorithm-level solutions applied}

\section{Conclusions}

The main conclusions for this chapter.


