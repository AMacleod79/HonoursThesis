\chapter{Literature Review}\label{ch:Background}

This chapter provides some background research on the project and examines some work carried out in the area of research. Firstly, the chapter will give an overview of Machine Learning in general, then supervised machine learning will be discussed in greater details. The chapter will then focus on the use of Machine Learning in the Healthcare sector and the work currently being done in this area. Finally the challenges that arise with the use of machine learning with healthcare related datasets will then be explored.  

\section{Machine Learning}
Machine learning is considered to be a branch of artificial intelligence and has been around for decades. It has been defined by Arthur Samuel as ''the programming of a digital computer to behave in a way which, if done by human being or animals would be described as involving the process of learning'' \citep{Samuel:1959vp}.  Technological advances since then have meant that considerable amount of data have been produced and will need to be analyzed. A report by the EMC corporation estimates that newly generated data will grow 40\% a year and that by 2020, the size of the ''digital universe'' will reach 44 zettabytes \citep{EMC:2014ve}. Despite the larger quantity of data being produced daily, as of 2013, only 22\% of the data generated worldwide was considered useful if it were tagged, and less than 5\% was actually analyzed. It is estimated, however that proportion of the data considered useful is likely to reach 35\% by 2020, mostly due to the growth of data from embedded systems \citep{EMC:2014ve}. 
This growth in data production and the advances in computing generally means that the field of machine learning and artificial intelligence have also seen growth and are expected to continue growing \citep{Colombus:wm}. Recent decades have seen sharp increases in computing speed, in turn allowing systems to collect and process large quantities of data very rapidly \citep{Denning:2016fz} . At the same time as computing power increased, the cost of both transistors and storage have decreased markedly: from \$222 per million transistors in 1992 to \$0.06 per million transistors in 2012 and from \$569 per gigabyte of storage in 1992 to \$0.03 per gigabyte in 2012 \citep{Hagel:2013ur}. These two factors combined with increased availability of competent graduates in the field of AI as well as cultural acceptance from the public have allowed the field of machine learning to expand \citep{Evans:sHGdqFvY}. Indeed in 2017, Deloitte predicted that 300 millions smart phones would have on-board neural network machine learning capabilities, meaning that pattern recognition could happen in some instances (e.g. language translation, navigation) without network connectivity \citep{Deloitte:2017wo}.

Although machine learning represents a number of algorithms, it can be broadly categorized in two types: supervised and unsupervised learning. In supervised learning, the learning agent will observe some example input-output pairs and learns a function that maps from input to output \citep{Russell:2016tz}. In other words, the goal of supervised learning is to learn a function that can best approximate the relationship between input and output observable in the data \citep{Mullainathan:uy}. 
In contrast in unsupervised learning, the tasks are generally clustering, representation learning or density estimation, i.e. learning the inherent structure of the data without explicitly-provided labels. The lack of labels means that there is no specific way to measure model performance in unsupervised learning \citep{Soni:tr}.

\begin{figure}[h]
\caption{Types of machine learning}
\centering
\includegraphics[width=0.7\textwidth]{ThesisTemplate/usingLatex/images/Figure1.png}
\end{figure}



Machine learning is used in many different sectors from finance to healthcare, through to education and customer relations. Many machine learning algorithms are now used to assist decision making in many fields (e.g. credit scoring, medical diagnostic) and many have shown very high performance. It is important however to point out that each algorithm will have a True Positive rate, a False Positive rate, a True Negative rate and a False Negative rate.

Here include diagram to show what they are (from big data module). 
These numbers must be known when decisions are being made as in the cases of very high performing algorithms, there is an increased chance of false positives, which could have unintended real-life consequences (for example in the field of medicine, if a diagnostic of serious illness is made by the algorithm but the patient is healthy, they may have to undergo unnecessary tests to confirm the diagnostic). Equally, a less performing algorithm will a higher rate of false negatives which could also have dire consequences. There are obviously ethical and moral considerations to be taken into account when machine learning algorithms are developed for decision making with real life implications. 



\section{Supervised Machine Learning}
\subsection{Definition}
Supervised learning is typically carried out in the context of classification (mapping input to output labels) or regression problems (mapping input to continuous output). In both cases, the aim is to establish a specific relationship in the input data that will allow the output data to be correctly labelled \citep{Soni:tr}. In supervised learning, model complexity and bias-variance trade-off have to be considered and they are in fact interrelated.
\subsection{Evaluating Performance}

There are many ways to evaluate the performance of a supervised learning algorithms. These are explained in Figure 2.2 and these different metrics can help assess the usefulness of a model. Of particular interest in the field of healthcare are the True Positive, False Positive, True Negative and False negative rate as these can have real life devastating consequences on patients.

\begin{figure}[h]
\caption{Evaluating the performance of an algorithm: For a binary classifier that classifies data points to be a member of either a positive class or a negative class, the following definitions are used in the measure formulas: True positive (TP)— a correct classification that a data point is a member of the positive class. True negative (TN)—a correct classification that a data point is a member of the negative class. False positive (FP)—an incorrect classification that a data point is a member of the positive class. False negative (FN)—an incorrect classification that a data point is a member of the negative class. For a classifier that predicts the probability of an outcome,pi is the predicted probability of the outcome for data point i, and oi is the whether the outcome was observed for that data point or not(adapted from \citep{Callahan:2017bz})}
\centering
\includegraphics[width=0.7\textwidth]{ThesisTemplate/usingLatex/images/AlgPerformance.png}
\end{figure}

\section{Machine Learning in Healthcare}
\subsection{Motivation: data in healthcare}
One key area where machine learning is being invested in is the healthcare sector \citep{Obermeyer:2016ju,EMC:2014ve, Evans:sHGdqFvY}. Indeed data growth in this sector has been growing at a faster rate than other sectors (48\% annual growth versus 40\% growth on average for other sectors) according to a report from EMC \citep{EMC:2014ve}. And it is thought that new healthcare applications will drive data growth. For example, the adoption of Electronic Health Record (EHR) in the United States by healthcare providers (hospitals, GP) is growing so fast that it is estimated that by 2020, penetration of EHR in the US market will reach 95\%. Further, increasingly stringent regulations of data protection and maintenance, especially in the healthcare sector means that many providers choose to keep data indefinitely \citep{EMC:2014ve}.  However large amounts of this data is still largely unused and according to the EMC corporation, better data analytics will help identify the most useful data, which will in turn enable information-driven decision.
The healthcare sector also faces challenges in most parts of the world. Firstly, the global population is ageing. According to data collected by the United Nation Department of Economic and Social Affairs (Population Division), the number of older persons (60 years or over) is estimated to more than double by 2050, rising from 962 million globally in 2017 to 2.1 billion in 2050, meaning that population aged 60 or over is growing faster than all younger age groups \citep{UnitedNations:2017wd}. An ageing population with longer life expectancy will make more demands on the health services everywhere. A second challenge of the sector is the shortage of physicians and other care providers. For example in the United States, the number of primary care physicians is expected to increase by only 8\% whereas the demand for primary care physicians will rise by 14\% resulting in a shortfall of around 20, 400 physicians \citep{EMC:2014ve}. The trend is similar in the UK and other European countries (need ref here). At the same time, patient expectations will increase as people will expect treatments and care in line with technological developments.\newline
Together these factors  mean that the healthcare sector needs to adapt and to be able to deliver care in the most efficient way and will need to turn to Information Technologies in general to help scaling the process, and to machine learning in particular in order to facilitate a greater output of robust diagnosis, uncover novel drug candidates, or detect best possible treatment given a patient's background.\newline

\subsection{Opportunities for machine learning in healthcare}
Although the use of machine learning in healthcare is not new (there are many commonly used teaching healthcare related datasets from studies done in the 1980s and 1990s, the Breast Cancer Dataset for example was first used in a study published in 1994 \citep{OLMangasarian:1994ue} and the Pima Indian Diabetes dataset was used in a study from 1988 \citep{Smith:1988wy}), recent years have seen an increase in publications relating to machine learning and healthcare, most likely driven by the general growth in machine learning centred research as discussed in the previous section but also by the increasing volume of data being produced \citep{Pesapane:2018kv} see Figure 2.3.\newline

\begin{figure}[h]
\caption{}
\centering
\includegraphics[width=0.7\textwidth]{ThesisTemplate/usingLatex/images/PesapaneFig.png}
\end{figure}

The previous chapter discussed briefly the potential of machine learning to greatly help in the field of epidemiology by providing an alternative to randomised control trials (RTC) or case-control studies by exploiting large patient datasets which are now available in electronic format across large geographical areas \citep{Callahan:2017bz}, through the adoption of EHR. Studies where machine learning has been applied to EHR are increasingly popular \citep{Goldstein:2017bk}. \newline 
EHR data differs from to traditional cohort based risk-studies since the data may not be standardised, is generally collected more frequently and is collected without the use strict inclusion requirements. 
There are advantages to the use of EHR data as they are typically collected more often than those from cohort studies and will more often reflect real-world situations than the data obtained from restrictive cohort studies. In one such case, a model to predict heart failure survival was built using EHR data from the Mayo Clinic \citep{Panahiazar:2015gp}. The authors compared their model to the existing Seattle model and found that the use of EHR data provided a model that was more accurate (11\% AUC improvement) and more convenient to use in clinical setting. Panahiazar and colleagues suggested that one of the reason their model showed better predictions than the existing one is that the Seattle Heart Failure Model (SHFM) is extrapolated from clinical trial databases and therefore does not always reflect real-life situations.
There are many more areas where machine learning could improve healthcare delivery such as the stratification of patients into risk category or to characterise and predict a variety of health risk, as well as early diagnostic of certain condition. The literature abounds with examples of successful machine learning algorithms which have been developed with these goals in mind. \newline 
Traditional risk scoring system can be flawed as some of the features used to compute the score may not reflect a wide enough variety of the population \citep{Besseling:2017bs}. Those limitations have led several group to turn to machine learning to build robust statistical models that will classify individuals appropriately and provide accurate level of risks \citep{Callahan:2017bz, Besseling:2017bs}.\newline
 Several research groups have successfully developed algorithms that outperformed existing stepwise logistic regression models to predict the risk of mortality of an individual or to diagnose a condition in a patient. For instance  Ross and colleagues developed a machine learning algorithm to identify the presence of peripheral artery disease (PAD) and predict future mortality risk \citep{Ross:2016kh}.The data used in this study was derived from a prospective observational study with a view to identify key demographic, clinical and genomic factors that differs between those presenting with PAD and those that do not. The disease was not used as a factor for enrolling patient in the study, however patients enrolled included those referred for complaints of angina, dyspnea or had abnormal stress results. Clinical data were obtained at enrolment and patients were followed for observation of any adverse event. Therefore there is a small element of bias in the sample used to build the algorithm, although the presence of PAD was not known at enrolment, the patients were already being enrolled in a study because of a number of complaints. \newline
 To build the model, the researchers included any variable for which a majority of patient had a data value. In other words, no variable was included based on \textit{a priori} hypotheses and patients were included if they had complete data. The researchers were able to build a Random Forest-based algorithm that successfully identified undiagnosed PAD (AUC:0.84). The model was also used to predict mortality (AUC:0.76). PAD is highly prevalent as well as difficult to diagnose, so this algorithm could prove very useful in a clinical setting.\newline
 Despite the algorithm performance, there are several limitations to this study. Firstly the algorithm was constructed using only those patients with complete data. This is problematic for clinical application, as patient records are often incomplete (as discussed previously) for a variety of reasons. The authors suggest the possible imputation of data in cases of missing values \citep{Ross:2016kh}. As previously mentioned, the population used to train the algorithm is already considered  to be high-risk, thus the algorithm may not generalise well to other populations. \newline
 Other efforts at patient risk classification have been made  and by other groups have included the application of machine learning to the selection of individuals for genetic testing for familial hypercholesterolemia (FH) \citep{Besseling:2017bs} in an attempt to improve current selection criteria which tend to misclassify certain population, especially young individuals.\newline
 The work carried out by Besseling and colleagues provided a useful model which showed good discrimination and calibration, which compared to existing models allowed for better inclusion of young persons (which the previous models tended to exclude) and this new model is being considered for use in clinical setting. This work allows for the selection of individual for genetic testing which is often expensive and therefore needs to be targeted. The model is to be used on patients with suspicion of FH rather than the population at large.\newline
 Other areas of healthcare where machine learning has been successfully applied include imaging diagnostic, as early as 1994 \citep{OLMangasarian:1994ue} and more recently Aissa and colleagues investigated the impact and clinical performance of a machine learning based tool for the detection of lung nodule in melanoma patients \citep{Aissa:2018jm}. \newline
 The diagnostic of lung nodules is one of the criteria to identify metastases in cancer patients as well as being used for screening of primary malignancies of the lung. The presence of lung nodules in melanoma patients the presence of pulmonary metastatic disease is an indicator of worsen prognosis so its accurate identification is important. In this study the authors compared the reading of CT scans by three radiologists to that of a computer aided detection system (CAD). This novel CAD system is machine learning based and the additional vessel-suppressed reconstruction can be viewed by the radiologist. \newline
 The CAD system did not miss any of the nodules identified by the radiologists also reviewing the images, however the system found additional nodules, which were missed by the radiologists. These turned out to be very small and did not affect therapy. In 9\% of these cases, theses nodules turned out to be false positives and follow up analyses revealed that none of the nodules detected by CAD but missed by radiologist were metastases or would have led to changes of therapy. In 30\% of the cases where the nodules where missed by the radiologist, they were so small that they could not be definitely labelled as benign or not, which means patients needed to be further referred for follow-up. This could lead to further follow-ups and increased costs as well as patient distress. This study suggests that machine learning aided diagnostic can be of great help particularly in cases where early detection of disease is crucial to patient survival, but the authors stress that findings need to then be reviewed by the appropriate specialists (in this case radiologist) in order to be appropriately interpreted and the CAD system should be used as either second reader or concurrent reader. It is worth noting that the study concerned only a relatively sample size (46 patients) and larger sample sizes may have shown a different false positive result, or the presence of nodules missed by either the CAD system or the radiologists.\newline
 The studies discussed above all show that machine learning can be a powerful tool for diagnostic medicine although there are limitations inherent to the study design or the choice of dataset and these are discussed in section 2.4.\newline
Machine learning could also be useful in hospital and practice management, for example to predict demand for emergency department beds or to inform staffing decision \citep{Callahan:2017bz, Tiwari:2014bq}. These applications have the potential to be useful especially in environment for resources are scarce and they present challenges quite different to those centred around patient diagnostic or disease risk predictions. For the purpose of this review, this aspect of machine learning in a healthcare setting will no be discussed further and is only mentioned here for indicative purposes.


\section{Challenges in healthcare}
\subsection{Challenges inherent to the data}
The use of machine learning as applied to healthcare related data is not without challenges. 
Electronic health record data present some difficulties as EHR data is captured for all patients mostly when they are unwell and collect only those metrics that the clinician will think is appropriate for a particular visit, and this can introduce bias in the data \citep{Hersh:2013gp, Goldstein:2017bk}. \newline 
Goldstein and colleagues looked at a large number of EHR and machine learning based studies and analysed both their methodologies and result to  establish areas of weakness and suggestions for future studies to remedy those problems. They identified four main areas where improvements were necessary in order to get the best possible results for EHR based studies: 
\begin{itemize}
    \item Many studies were not carried across multiple centres or did not cross validate using data from another centre, which does not guarantee the portability of the model 
    \item Predictor variables were not always used to the fullest extent of the EHR data and better leverage from the available information could be gained by using time-varying factors
    \item Bias inherent to the data (EHR data contains sicker people on average) is not always addressed which could in turn affect the robustness of the model
    \item Evaluation metrics were often not suited to the data or the model (c-statistic) and should instead have used Predictive Positive Value or Net benefit metrics. 
\end{itemize}

Conversely, although EHR data tend to be biased towards a higher rate of sick patients, many health-related dataset can be biased towards healthy patients, especially when using cohort-based data. In this case, there are only a small subset a patient with the disease or marker that is being investigated and this can lead to developing models that will easily fail to identify the targeted outcome because the training sets do not contain enough instances of the "sick" label compare to the "healthy" label.
This problem can be resolved through stratification of the data or changing from a binary category to a multiple category.
Another common challenge from working with health-related dataset is the problem of missing data. It is especially common when working with EHR \citep{Goldstein:2017bk} but can also happen when working with cohorts and this problem was discussed in several of the examples discussed previously \citep{Besseling:2017bs, Ross:2016kh}.\newline
Both studies resorted to data imputation \textit{i.e} the process of replacing missing data with substituted values. This is often done by replacing the missing values with the median value for that variable. Ross and colleagues even report, although this is not published that imputation of missing data may improve predictive accuracy \citep{Ross:2016kh}.\newline
In the studies described in section 2.3, there were several methodological considerations and limitations that were taken into account by the authors. The inclusion or not of variables towards the final model is one such consideration. Often a stepwise selection, without considering previously known association between candidate predictors and outcome, is used. However this might exclude variables that appear statistically insignificant in a multivariable model but would be significant when used in another cohort and may therefore impact the portability of the model. In contrast, by using only variables that have been previously shown to contribute to the outcome while ignoring those that show association in the data, the model risk missing important associations that are yet to be identified \citep{Besseling:2017bs}. To avoid either of these pitfalls, Besseling and colleagues chose to use a two-step approach in choosing the candidate predictors: 
 \begin{itemize}
 \item firstly all variables considered important (based on current literature regarding clinical phenotype of FH) were included in a preliminary model;
 \item then the authors added a combination of eight variables to the model, with a maximum of four added at any time.
\end{itemize}
In contrast the model to identify PAD described by Ross and colleagues \citep{Ross:2016kh} was built by using all variables for which data was available so as to limit deliberate bias in choosing which variables to include in the model.\newline
The size of the dataset used for a study is also of notable considerations as smaller dataset can lead to bias and overfitting  of the data \citep{Steyerberg:2003fq}. Though many studies using machine learning use large datasets, many fail to use multiple centres which may reduce the utility of the model when extrapolated to different population and this has been noted by Goldstein and colleagues \citep{Goldstein:2017bk}.  The familial hypercholesterolemia model built by Besseling and colleagues successfully avoided this pitfall using a large training dataset and using an external validation set from a different cohort \citep{Besseling:2017bs}. In the case of the PAD model study, the authors acknowledged that their training size was relatively small and from patients that had been chosen because their data were complete and this could limit use of the model in a clinical setting \citep{Ross:2016kh}.\newline


\subsection{Data access}
Patient level data is considered sensitive data and is therefore protected. In the UK it falls under the Data Protection Act (1998) and there are similar laws in place across many other countries.\newline
In order to use patient level data for research purposes, consent of each patient has to be obtained, unless the data is processed so as to be anonymised and collated in such a way that no individual patient can be  identified from their data. In the UK, the CPRD (Clinical Practice Research Datalink) is responsible for collecting de-identified data from a network of GP practices. This data can be accessed by research groups through an application process. Other de-identified data are released by NHS digital for NHS England and by Information Data Service for NHS Scotland.
Other collected-for purposes data can be obtained in the same way as they are obtained for clinical trials. A number of datasets that have been used for published research have now been placed in a de-identified format in the public domain through organisation such as Kaggle or UCI. Many datasets relating to healthcare can be found on these websites and used to create new algorithms or compare the performance of different algorithms on specific datasets.
There are a growing numbers of wearables that collect health-related individual data, however these tend to be protected by data protection laws and the various private companies in charge of hosting the data may not share them with researchers unless consent has been explicitly seeked from the user. Finally, there has been growing enthusiasm from the public in genomic level data and for profit organisation such as 23AndMe have seen a growing number of customers looking to find out more about their disease risk or ancestry through DNA testing. These companies have various consent policies and will either not share the data or will seek consent of the consumer to share data with selected partners. 


\subsection{Cultural Challenges: response from healthcare staff and patient}
Although the use of machine learning in the healthcare sector appears to be growing at least in a research setting, its full implementation in clinical setting is still facing some opposition from providers \citep{Cabitza:2017hv}. Though some view the growing use of AI and machine learning in healthcare as inevitable \citep{Murdoch:2013hm} and there are advocates for opening data use in healthcare \citep{Kostkova:2016ur} and many see it as tool which can support rather than replace medical providers \citep{Pesapane:2018kv}.
Although there are some reticences from patient in sharing their health cata for research purposes \citep{Goldacre:tf}, there is evidence that these attitudes may be shifting \citep{Kostkova:2016ur}. 

\section{Conclusions}

This chapter has reviewed the existing literature relevant to the use of machine learning in the field of healthcare. This review has identified several areas where problems exist. \newline 
First there are some bias inherent to the data used in healthcare-related studies and these bias need to be addressed during data pre-processing if helpful models are to be developed.\newline
Second access to data can be difficult and this may be an issue for this particular project though there are many publicly available datasets and although these are not patient level data, they could be helpful to build a number of algorithms and assessing the effects of data stratification and feature engineering on the performance of the models. Investigation of these issues will also hopefully help address the issues of bias in the data.\newline
A third category of problem broached while reviewing the literature and relating to data access is the issue of consent to use of data, data protection and more generally health provider and patient attitude toward the use of machine learning in healthcare, however this falls outwith the scope of this project and will not be discussed further. 




