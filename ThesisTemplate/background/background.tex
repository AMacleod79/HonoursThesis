\chapter{Literature Review}\label{ch:Background}

This chapter provides some background research on the project and examines some work carried out in the area of research. Firstly, the chapter will give an overview of Machine Learning in general, then supervised machine learning will be discussed in greater details. The chapter will then focus on the use of Machine Learning in the Healthcare sector and the work currently being done in this area. Finally the challenges that arise with the use of machine learning with healthcare related datasets will then be explored.  

\section{Machine Learning}
Machine learning is considered to be a branch of artificial intelligence and has been around for decades. It has been defined by Arthur Samuel as ''the programming of a digital computer to behave in a way which, if done by human being or animals would be described as involving the process of learning'' \citep{Samuel:1959vp}.  Technological advances since then have meant that considerable amount of data have been produced and will need to be analyzed. A report by the EMC corporation estimates that newly generated data will grow 40\% a year and that by 2020, the size of the ''digital universe'' will reach 44 zettabytes \citep{EMC:2014ve}. Despite the larger quantity of data being produced daily, as of 2013, only 22\% of the data generated worldwide was considered useful if it were tagged, and less than 5\% was actually analyzed. It is estimated, however that proportion of the data considered useful is likely to reach 35\% by 2020, mostly due to the growth of data from embedded systems \citep{EMC:2014ve}. 
This growth in data production and the advances in computing generally means that the field of machine learning and artificial intelligence have also seen growth and are expected to continue growing \citep{Colombus:wm}. Recent decades have seen sharp increases in computing speed, in turn allowing systems to collect and process large quantities of data very rapidly \citep{Denning:2016fz} . At the same time as computing power increased, the cost of both transistors and storage have decreased markedly: from \$222 per million transistors in 1992 to \$0.06 per million transistors in 2012 and from \$569 per gigabyte of storage in 1992 to \$0.03 per gigabyte in 2012 \citep{Hagel:2013ur}. These two factors combined with increased availability of competent graduates in the field of AI as well as cultural acceptance from the public have allowed the field of machine learning to expand \citep{Evans:sHGdqFvY}. Indeed in 2017, Deloitte predicted that 300 millions smart phones would have on-board neural network machine learning capabilities, meaning that pattern recognition could happen in some instances (e.g. language translation, navigation) without network connectivity \citep{Deloitte:2017wo}.

Although machine learning represents a number of algorithms, it can be broadly categorized in two types: supervised and unsupervised learning. In supervised learning, the learning agent will observe some example input-output pairs and learns a function that maps from input to output \citep{Russell:2016tz}. In other words, the goal of supervised learning is to learn a function that can best approximate the relationship between input and output observable in the data \citep{Mullainathan:uy}. 
In contrast in unsupervised learning, the tasks are generally clustering, representation learning or density estimation, i.e. learning the inherent structure of the data without explicitly-provided labels. The lack of labels means that there is no specific way to measure model performance in unsupervised learning \citep{Soni:tr}.

Machine learning is used in many different sectors from finance to healthcare, through to education and customer relations. Many machine learning algorithms are now used to assist decision making in many fields (e.g. credit scoring, medical diagnostic) and many have shown very high performance. It is important however to point out that each algorithm will have a True Positive rate, a False Positive rate, a True Negative rate and a False Negative rate.

Here include diagram to show what they are (from big data module). 
These numbers must be known when decisions are being made as in the cases of very high performing algorithms, there is an increased chance of false positives, which could have unintended real-life consequences (for example in the field of medicine, if a diagnostic of serious illness is made by the algorithm but the patient is healthy, they may have to undergo unnecessary tests to confirm the diagnostic). Equally, a less performing algorithm will a higher rate of false negatives which could also have dire consequences. There are obviously ethical and moral considerations to be taken into account when machine learning algorithms are developed for decision making with real life implications. 



\section{Supervised Machine Learning}
Supervised learning is typically carried out in the context of classification (mapping input to output labels) or regression problems (mapping input to continuous output). In both cases, the aim is to establish a specific relationship in the input data that will allow the output data to be correctly labelled \citep{Soni:tr}. In supervised learning, model complexity and bias-variance trade-off have to be considered and they are in fact interrelated.


Definition, Evaluation, ...Challenges

\section{Machine Learning in Healthcare}

One key area where machine learning is being invested in is the healthcare sector \citep{Obermeyer:2016ju,EMC:2014ve, Evans:sHGdqFvY}. Indeed data growth in this sector has been growing at a faster rate than other sectors (48\% annual growth versus 40\% growth on average for other sectors) according to a report from EMC \citep{EMC:2014ve}. And it is thought that new healthcare applications will drive data growth. For example, the adoption of Electronic Health Record (EHR) in the United States by healthcare providers (hospitals, GP) is growing so fast that it is estimated that by 2020, penetration of EHR in the US market will reach 95\%. Further, increasingly stringent regulations of data protection and maintenance, especially in the healthcare sector means that many providers choose to keep data indefinitely \citep{EMC:2014ve}.  However large amounts of this data is still largely unused and according to the EMC corporation, better data analytics will help identify the most useful data, which will in turn enable information-driven decision.
The healthcare sector faces challenges in most parts of the world. Firstly, the worldâ€™s population is aging. According to data collected by the United Nation Department of Economic and Social Affairs (Population Division), the number of older persons (60 years or over) is estimated to more than double by 2050, rising from 962 million globally in 2017 to 2.1 billion in 2050, meaning that population aged 60 or over is growing faster than all younger age groups (United NationsDepartment of Economic Social Affairs, Population Division 2017). An ageing population with longer life expectancy will make more demands on the health services everywhere. A second challenge of the sector is the shortage of physicians and other care providers. For example in the United States, the number of primary care physicians is expected to increase by only 8% whereas the demand for primary care physicians will rise by 14% resulting in a shortfall of around 20, 400 physicians (EMC 2014). The trend is similar in the UK and other European countries (need ref here). At the same time, patient expectations will increase as people will expect treatments and care in line with technological developments. Together these factors  mean that the healthcare sector needs to be able to deliver care in the most efficient way and will need to turn to Information Technologies in general to help scaling the process, and to machine learning in particular in order to facilitate a greater output of robust diagnosis, uncover novel drug candidates, or detect best possible treatment given a patient background. 
Although the use of machine learning in healthcare is not new (there are many commonly used teaching healthcare related datasets from studies done in the 1980s and 1990s, the Breast Cancer Dataset for example was first used in a study published in 1994 (O L Mangasarian 1994) and the Pima Indian Diabetes dataset was used in a study from 1988 (Smith et al. 1988)), recent years have seen an increase in publications relating to machine learning and healthcare, most likely supported by the general growth in machine learning centered research as discussed previously but also by the increasing volume of data being produced (Pesapane et al. 2018).
As mentioned briefly in the previous chapter, machine learning has the potential to greatly help in the field of epidemiology by providing an alternative to randomized control trials (RTC) or case-control studies by exploiting large patient datasets that are now available in electronic format across large geographical areas (Callahan & Shah 2017), through the adoption of EHR. Studies where machine learning has been applied to EHR are increasingly popular (Goldstein et al. 2017). EHR data differs from to traditional cohort based risk-studies since the data may not be standardized, is generally collected more frequently and is collected without the use strict inclusion requirements. This in turn presents some difficulties as EHR data is captured for all patients mostly when they are unwell and collect only those metrics that the clinician will think is appropriate for a particular visit, and this can introduce bias in the data(cite Hersh here?). There are however advantages to the use of EHR data as they are typically collected more often than those from cohort studies and will more often reflect real-world situations than the data obtained from restrictive cohort studies. Goldstein and colleagues looked at a large number of EHR based studies and analyzed both their methodologies and result to  establish areas of weakness and suggestions for future studies to remedy those problems. They identified four main areas where improvements were necessary in order to get the best possible results for EHR based studies: 
-	Many studies were not carried across multiple centers or did not cross validate using data from another center, which does not guarantee the portability of the model 
-	Predictor variables were not always used to the fullest extent of the EHR data and better leverage from the available information could be gained by using time-varying factors
-	Bias inherent to the data (EHR data contains sicker people on average) is not always addressed which could in turn affect the robustness of the model
-	Evaluation metrics were often not suited to the data or the model (c-statistic) and should instead have used Predictive Positive Value or Net benefit metrics.


\section{Challenges in Healthcare}



\section{Conclusions}

The main conclusions for this chapter.


